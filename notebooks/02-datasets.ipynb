{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_utils import showAttribs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module: eliana.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElianaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElianaDataset       : High level class for Eliana Dataset Manipulation, oriented to pandas DataFrames.\n",
      "\n",
      "Constructor\n",
      "================\n",
      "__init__            : Common methods for Eliana Dataset Manipulation.\n",
      "\n",
      "Properties\n",
      "================\n",
      "data_dir            : Path for the raw data directory, including dataset_name().\n",
      "index               : Alias for meta for backward compatibility.\n",
      "meta                : Contains the metadata of the dataset.\n",
      "meta_filename       : Full path for the index filename.\n",
      "processed_dir       : Path for the processed data directory, including dataset_name().\n",
      "\n",
      "Methods\n",
      "================\n",
      "do_query_meta       : Code to generate the metadata of the dataset. Must be overloaded!\n",
      "do_query_trace      : Code to generate the log trace between two timestamps. Must be overloaded!\n",
      "load_trace          : Load a raw trace based on its ID in the metadata.\n",
      "preload_traces      : Preloads traces for faster access.\n",
      "set_dict_for_trace_filenames: Sets unique identifiers for trace filenames. This must be overriden.\n",
      "signature           : When inherited, add the new signatures to the right:\n",
      "trace_filename      : Returns the cached trace filename for a given index number.\n",
      "traces              : Load and concatenate traces from the metadata.\n"
     ]
    }
   ],
   "source": [
    "from eliana.datasets import ElianaDataset\n",
    "\n",
    "showAttribs(ElianaDataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parlogs Observations\n",
    "\n",
    "Public dataset in Huggin Faces, at https://huggingface.co/datasets/Paranal/parlogs-observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParlogsObservations : Public Dataset with VLTI logs from 2019.\n",
      "\n",
      "Constructor\n",
      "================\n",
      "__init__            : Documentation pending\n",
      "\n",
      "Properties\n",
      "================\n",
      "available_periods   : \n",
      "available_sources   : \n",
      "available_systems   : \n",
      "data_dir            : Path for the raw data directory, including dataset_name().\n",
      "index               : Alias for meta for backward compatibility.\n",
      "meta                : Contains the metadata of the dataset.\n",
      "meta_filename       : Full path for the index filename.\n",
      "period              : Documentation pending\n",
      "processed_dir       : Path for the processed data directory, including dataset_name().\n",
      "source              : Documentation pending\n",
      "system              : Documentation pending\n",
      "\n",
      "Methods\n",
      "================\n",
      "do_query_meta       : Generates the metadata for the dataset.\n",
      "do_query_trace      : Generates the trace for the dataset based on the row of metadata.\n",
      "load_trace          : Load a raw trace based on its ID in the metadata.\n",
      "preload_public_file : Documentation pending\n",
      "preload_traces      : Preloads traces from parket files.\n",
      "set_dict_for_trace_filenames: Sets unique identifiers for trace filenames. This must be overriden.\n",
      "signature           : Documentation pending\n",
      "trace_filename      : Returns the cached trace filename for a given index number.\n",
      "traces              : Loads and concatenates traces from the metadata.\n"
     ]
    }
   ],
   "source": [
    "from eliana.datasets import ParlogsObservations\n",
    "\n",
    "showAttribs(ParlogsObservations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticsearchQueryDataset\n",
    "\n",
    "Class specific to manipulate Elasticsearch or Opensearch queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticsearchQueryDataset: Parlogan dataset specialized in Elasticsearch queries.\n",
      "\n",
      "Constructor\n",
      "================\n",
      "__init__            : Main parameter: **config\n",
      "\n",
      "Properties\n",
      "================\n",
      "data_dir            : Path for the raw data directory, including dataset_name().\n",
      "index               : Alias for meta for backward compatibility.\n",
      "meta                : Contains the metadata of the dataset.\n",
      "meta_filename       : Full path for the index filename.\n",
      "processed_dir       : Path for the processed data directory, including dataset_name().\n",
      "start_timestamp     : Start timestamp for this dataset instance.\n",
      "stop_timestamp      : Stop timestamp for this dataset instance.\n",
      "\n",
      "Methods\n",
      "================\n",
      "add_trace_filter    : Add filters to trace query: (trace_query) -(filter1 OR filter2 ...)\n",
      "do_query_meta       : Code to generate the metadata of the dataset. Must be overloaded!\n",
      "do_query_trace      : Code to generate the log trace between two timestamps. Must be overloaded!\n",
      "filtered_trace_query: Returns (self.trace_query) -(filter1 OR filter2 ...)\n",
      "load_trace          : Load a raw trace based on its ID in the metadata.\n",
      "preload_traces      : Preloads traces for faster access.\n",
      "set_dict_for_trace_filenames: Sets a dictionary with unique identifiers for trace filenames based on the START time in\n",
      "signature           : When inherited, add the new signatures to the right:\n",
      "trace_filename      : Returns the cached trace filename for a given index number.\n",
      "traces              : Load and concatenate traces from the metadata.\n"
     ]
    }
   ],
   "source": [
    "from eliana.datasets import ElasticsearchQueryDataset\n",
    "\n",
    "showAttribs(ElasticsearchQueryDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log2Table\n",
    "Utility to read a sequential set of events and fill a table with complex behavior. It is based on finite state machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2Table           : Parse a list of events following a criteria based in state machines to fill a table with complex behavior.\n",
      "\n",
      "Constructor\n",
      "================\n",
      "__init__            : Constructor\n",
      "\n",
      "Properties\n",
      "================\n",
      "\n",
      "Methods\n",
      "================\n",
      "parse               : Iterate DataFrame or list and create rows previously defined\n",
      "start_when          : Declare initialization of a row\n",
      "when                : Template to fill a column in a row based on its content\n"
     ]
    }
   ],
   "source": [
    "from eliana.datasets import Log2Table\n",
    "showAttribs(Log2Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "(TBD)\n",
    "* [Very simple example from a synthetic log](to_be_done)\n",
    "* [Longer example](to_be_done)\n",
    "* [Advanced behaviors](to_be_done)\n",
    "* [Mix with eliana.datasets](to_be_done)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
